{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet-Pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruXfpEa2rJCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "\n",
        "class Unet(nn.Module):\n",
        "\n",
        "    def double_conv(self, in_c, out_c):\n",
        "        conv = nn.Sequential(\n",
        "            nn.Conv2d(in_c, out_c, kernel_size = 3),\n",
        "            nn.ReLU(inplace = True),\n",
        "            nn.Conv2d(out_c, out_c, kernel_size= 3),\n",
        "            nn.ReLU(inplace = True)\n",
        "        )\n",
        "        return conv\n",
        "\n",
        "    def crop_img(self, tensor, target_tensor):\n",
        "        target_size = target_tensor.size()[2]\n",
        "        tensor_size = tensor.size()[2]\n",
        "        delta = tensor_size - target_size\n",
        "        delta = delta//2\n",
        "        return tensor[:,:,delta:tensor-delta, delta:tensor_size-delta]\n",
        "\n",
        "    def __init__(self): \n",
        "        super(Unet, self).__init__()\n",
        "        self.conv1 = self.double_conv(1, 64)\n",
        "        self.conv2 = self.double_conv(64, 128)\n",
        "        self.conv3 = self.double_conv(128, 256)\n",
        "        self.conv4 = self.double_conv(256, 512)\n",
        "        self.conv5 = self.double_conv(512, 1024)\n",
        "        self.conv6 = self.double_conv(512, 1024)\n",
        "        self.conv7 = self.double_conv(512, 1024)\n",
        "        self.conv8 = self.double_conv(512, 1024)\n",
        "        self.conv9 = self.double_conv(512, 1024)\n",
        "        self.conv10 = self.double_conv(512, 1024)\n",
        "\n",
        "        self.max_pool = nn.MaxPool2d(2, stride = 2)\n",
        "\n",
        "        self.conv11 = self.double_conv(1024, 512)\n",
        "        self.conv12 = self.double_conv(512, 256)\n",
        "        self.conv13 = self.double_conv(256, 128)\n",
        "        self.conv14 = self.double_conv(128, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x)#\n",
        "        x2 = self.max_pool(x1)\n",
        "        x3 = self.conv2(x2)#\n",
        "        x4 = self.max_pool(x3)\n",
        "        x5 = self.conv3(x4)#\n",
        "        x6 = self.max_pool(x5)\n",
        "        x7 = self.conv4(x6)#\n",
        "        x8 = self.max_pool(x7)\n",
        "        x9 = self.conv5(x8)#\n",
        "        x10 = nn.ConvTranspose2d(1024, 512, 2, 2)(x9)\n",
        "        x10 = torch.cat([x7, x10])\n",
        "        x11 = self.conv11(x10)\n",
        "        x12 = nn.ConvTranspose2d(512, 256, 2, 2)(x11)\n",
        "        x12 = torch.cat([x5, x12])\n",
        "        x13 = self.conv12(x12)\n",
        "        x14 = nn.ConvTranspose2d(256, 128, 2, 2)(x13)\n",
        "        x14 = torch.cat9([x3, x14])\n",
        "        x15 = self.conv13(x14)\n",
        "        x16 = nn.ConvTranspose2d(128, 64, 2, 2)(x15)\n",
        "        x16 = torch.cat([x1, x16])\n",
        "        x17 = self.conv14(x16)\n",
        "        x18 = nn.Conv2d(64, 2, kernel_size = 1)(x17)\n",
        "        #print(x18.size())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpzwJXjRrYZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = torch.rand(1, 1, 572, 572)\n",
        "unet = Unet()\n",
        "unet(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}